

# âœˆï¸ Flight Recommendation System with LLM Explanations

A **smart flight recommendation system** that suggests the best flights based on:

* âœ… Shortest travel time
* âœ… Least delays
* âœ… Eco-friendly options (low COâ‚‚ emissions)
* âœ… Dynamic natural language explanations using LLMs

This project integrates **traditional data science pipelines** with **Large Language Models (LLMs)** to make flight recommendations **explainable, user-friendly, and intelligent**.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ feature_engineering.py   # Preprocess raw flight dataset (25% sampled)
â”œâ”€â”€ flights_recommender.py   # Flight ranking logic (time, delays, CO2)
â”œâ”€â”€ llm_explainer.py         # Hugging Face LLM explanations
â”œâ”€â”€ utils.py                 # Shared utility functions
â”œâ”€â”€ logging_config.py        # Central logging setup
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ .env                     # Store your API tokens here (not committed)
â””â”€â”€ README.md                # This file
```

---

## âš™ï¸ Features

* ğŸ›  **Feature Engineering**:

  * Delay categorization
  * Time bucketization (hour of day, weekday/weekend)
  * Flight speed & COâ‚‚ estimation
  * Distance bucketing

* ğŸ” **Recommendation Engine**:

  * Rank flights based on weighted criteria (time, delay, COâ‚‚)
  * Flexible scoring logic

* ğŸ§  **LLM Explanations**:

  * Generates natural-language justifications for chosen flights
  * Runs with Hugging Face models (e.g., `distilgpt2`)
  * Compatible with **MPS acceleration** on Mac (Apple Silicon)

* ğŸ“Š **Logging & Debugging**:

  * Tracks model loading time, explanation generation, and pipeline steps

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Clone the repo

```bash
git clone <your-repo-url>
cd flight-recommendation
```

### 2ï¸âƒ£ Create and activate virtual environment

```bash
python3 -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set environment variables

Create a `.env` file in the root:

```
HF_API_TOKEN=your_huggingface_token
```

Get a free Hugging Face token here ğŸ‘‰ [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)

### 5ï¸âƒ£ Run the pipeline

**Feature engineering**

```bash
python feature_engineering.py
```

**Get flight recommendations**

```bash
python flights_recommender.py
```

**Generate LLM explanations**

```bash
python llm_explainer.py
```

---

## ğŸ–¥ Device Acceleration

* âœ… **Mac (Apple Silicon)** â†’ uses **MPS (Metal Performance Shaders)** automatically
* âœ… **CPU fallback** if MPS is unavailable
* ğŸš€ Future-ready for **CUDA (NVIDIA GPUs)** if running on Linux/Windows

---

## ğŸ“š Tech Stack

* **Python** ğŸ
* **Pandas, NumPy** â†’ Feature engineering
* **Scikit-learn** â†’ Preprocessing utilities
* **Hugging Face Transformers** â†’ LLM-based explanations
* **Dotenv** â†’ Secure API key management
* **Logging** â†’ Monitoring and debugging

---

## âœ… Example Output

**Input:** Flight dataset (25% sample)
**Output (ranked flights):**

```
Top recommended flights:
- Flight 123 from JFK to LAX, delay 5 mins, COâ‚‚ 120kg
- Flight 456 from SFO to ORD, delay 2 mins, COâ‚‚ 90kg
```

**LLM Explanation:**

```
The best choice is Flight 456 because it balances eco-friendliness with a very low delay risk, 
while Flight 123 is also good but has slightly higher emissions.
```

---

## ğŸ”® Future Enhancements

* ğŸŒ Integration with live flight APIs
* ğŸ“ˆ Full dataset training & scalability with Spark/Dask
* ğŸ§© Multi-modal AI (combine text + structured data)
* ğŸ¤ LLMOps integration for monitoring and feedback loops




[1] DEFINE ROLE & CONTEXT
   -> Specify expertise and purpose
   -> Include environment, libraries, constraints
   -> Example: â€œAct as senior ML engineer, AWS/Databricks environmentâ€

[2] PROVIDE DATA & GOALS
   -> Sample datasets, schemas, metrics
   -> Clear objective for output
   -> Example: â€œFeature engineering for flight delay prediction, optimize F1â€

[3] STRUCTURED PROMPT
   -> Specify output format & constraints
   -> Few-shot examples if needed
   -> Example: â€œReturn only Python code, single block, with commentsâ€

[4] MULTI-STEP CHAINING
   -> Break tasks into logical steps
   -> Step outputs feed next prompts
   -> Example: Features -> Code -> Refactor -> Explain -> Summarize

[5] ITERATIVE REFINEMENT
   -> Review output, request optimizations
   -> Handle edge cases, errors, performance
   -> Example: â€œRefactor code to handle missing data efficientlyâ€

[6] AUTOMATION & INTEGRATION
   -> Connect AI output to pipelines, dashboards, CI/CD
   -> Example: Generate ETL scripts or reports automatically

[7] VALIDATION & AUDIT
   -> Check AI outputs against reality/data
   -> Ensure correctness, safety, regulatory compliance

[8] SAVE & REUSE
   -> Store useful prompts, code snippets, summaries
   -> Build personal AI knowledge base

[9] CONTINUOUS IMPROVEMENT
   -> Adjust prompts for efficiency and clarity
   -> Learn from past interactions for faster, better results

